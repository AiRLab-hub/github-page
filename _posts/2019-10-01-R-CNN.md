---
layout: post
current: post
cover:  assets/images/posts/2019-10-01-R-CNN/figure9.png
navigation: True
title: R-CNN
date: 2019-09-30 15:00:00
tags: [paper-review]
class: post-template
subclass: 'post'
author: daehan
---

R-CNN Review

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 김대한 입니다. R-CNN을 시작으로 paper review post 를 작성하려고 합니다. ^_^

이번에 읽은 논문은 **R-CNN**(Rich feature hierarchies for accurate object detection and semantic segmentation) ([arXiv:1311.2524](https://arxiv.org/abs/1311.2524))입니다.

<hr>
#### **<u>Introduciton</u>** 

논문 발표 이전**SIFT**와 **HOG** 에 상당한 기반을 두고 visual recognition task를 수행했다고 합니다. 그러나 낮은 perpomance 로인해 R-CNN을 고안 하였습니다. 
여기서 SIFT와 HOG를 간단하게 설명하면, 다음과 같습니다.

**<u>SIFT</u>** 

![figure1](/assets/images/posts/2019-10-01-R-CNN/figure1.jpg)<br>

&nbsp;SIFT feature vector는 feature 주변의 영상패치를 4x4 블럭으로 나누고, (1) 각 블럭에 속한 pixel들의 gradient방향과 크기에 대한 histogram을 구하고 bin값으로 연결한 128차원 벡터 입니다.
- 크기, 형태, 방향에 강인하면서도 구분력이 뛰어나다.
- 기하학적 정보는 무시하고 feature 단위로 매칭을 수행한다. 

**<u>HOG</u>**

![figure2](/assets/images/posts/2019-10-01-R-CNN/figure2.jpg)<br>
&nbsp;HOG 는 대상 영역을 일정 셀로 분할한뒤, 각 셀마다 edge pixel들의 방향에 대한 histogram을 구한 뒤 이를 bin값으로 연결한 벡터 이다. (edge의 방향 histogram으로 본다.)<br>
블록 단위로는 기하학적 정보를 유지하고, 그 내부는 histogram을 사용하여 local변화에 어느정도 강인하다.

- template matching과 histogram maching에 중간 단계의 매칭방법이다.
- 기하학적 정보와 local 한 정보를 모두(일정 양) 가진다.
- figure2를 보면 알겠지만 edge의 방향정보를 사용하기 때문에 특이한(독특한) edge를 갖는 object를 식별하는데 적합한 영상 feature이다.

| SIFT/HOG| SIFT | HOG |
|---|:---|----------------------------------------------|
| `이용하는 정보` |  local information | edge information |
| `형태변화가 심한 경우 detection` | esay | difficult  |
| `example` | 액자속 그림(패턴) | 자동차, 배드민턴 라켓 |
| `**` | 복잡한 image | 단순하고 독특한 image |

<hr>

이 논문에서는 **HOG 기반의 시스템 보다 CNN을 사용하여 높은 performance를 보여주기 위해 2가지 문제**에 초점을 맞춥니다.<br>

<u>[One]</u> sliding-window 의 문제점을 파악하고 region proposal Algorithm을 사용했다.    

<center><img src="/assets/images/posts/2019-10-01-R-CNN/figure4.png"></center>
<center>(sliding-window method)</center><br>

<center><img src="/assets/images/posts/2019-10-01-R-CNN/figure5.png"></center> 
<center>(region-proposal method)</center><br>

- sliding window는 탐색해야하는 영역의 수가 이미지 전체이기 때문에 비효율적이고 입력 영상에 '물체가 있을거 같은' 영역을 빠른 속도로 찾아내는 region proposal algorithm을 사용 하였다.<br>
**결과적으로 search space가 훨씬 줄어들기 때문에 빠르고 효율적 이다.**

<u>[Two]</u> large CNN을 training하기 위한 충분한 dataset이 없었고, ILSVRC DATA로 pre-training 된 model을 가져와서 fine-tune 하여 PASCAL DATA에 적용하였다.

<hr>

#### **<u>object detection with R-CNN</u>**

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;R-CNN은 3가지의 module 로 구성되어 있습니다.
![figure3](/assets/images/posts/2019-10-01-R-CNN/figure3.png)<br>

1. region proposal을 얻어내는 module
2. CNN에 넣어 feture map을 얻어내는 module
3. CNN을 통해 추출된 feture map을 이용하여 Linear SVM을 사용하여 분류하는 module

이때, CNN model은 Alexnet을 거의 그대로 가져와 사용하였다.<br>
당연히 CNN은 고정 크기의 input을 입력으로 받기 때문에. region proposal을 CNN에 넣기 위해 crop & warp 를 한다.
논문에 나와있지만, 읽다보면 왜 R-CNN은 Classifier로 Softmax를 쓰지 않고 SVM을 사용했는지에 대한 의문이 들 수 있다. 근데 이는 수식적에 근간을 두고 사용한 것이 아닌 실험적인 결과로 Softmax를 사용했을때 mAP가 낮아졌기 때문에 SVM을 사용한 것 이다.(54.2% -> 50.9%)

SVM을 간단하게 설명하면 CNN으로 부터 추출된 featuer vector들을 class별로 점수를 주고 object인지 아닌지 object라면 어떤 object 인지 판별하는 classifier이다.

figure를 보면 Bbox reg 라는 부분이 있는데 bounding Box Regression인데 이는 필수로 사용해야 하는 부분은 아니라고 한다. 그러나 사용한 mAP가 더 좋기 때문에 사용하는 것을 권장한다. 
<center><img src="/assets/images/posts/2019-10-01-R-CNN/figure6.png" width="400" height ="300"></center>
<center>(Bounding-box method)</center><br>
ground-truth(G) 와 Predicted-Box(P) 가 있을때, P를 G로 mapping 해주는 것이다.

<center><img src="/assets/images/posts/2019-10-01-R-CNN/figure7.png" width="600" height ="300"></center>
<center>(Result)</center><br>
결과적으로, 다음과 같은 output을 얻을 수 있다.
<hr>

#### <u>논문을 읽으면서 여러자료들을 참고하여 R-CNN의 단점을 이해해 보았다.</u>
<center><img src="/assets/images/posts/2019-10-01-R-CNN/figure8.png" width="900" height ="200"></center>
<center>(Table)</center><br>
위와 같이 VOC2010 test에서 좋은 성능을 보였지만 단점은 존재한다.

1. region proposal된 약 2K의 image를 모두 crop하고 warp하는 과정에서 cpu를 통해 이뤄지기 때문에, 매우 비효율 적이라는 점을 이해하였다.<br>
   **직접 경험해본 일화**중 하나는, 1980x1080 를 224x224 image preprocessing 하는 과정이 오래걸려서 GPU가 놀고 있는 시간이 많았던 적이 있다. (224x224 image를 따로 저장하여 문제 해결.)

2. 3가지의 module을 따로 학습해야하기 때문에 비효율적이다.
   **때문에 Fast_R-CNN에서 Multi-task loss**를 사용한다.

3. end-to-end 학습이 불가능 하다.




