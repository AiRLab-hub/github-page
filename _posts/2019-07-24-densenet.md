---
layout: post
current: post
cover:  assets/images/posts/2019-07-24-densenet/cover.png
navigation: True
title: DenseNet
date: 2017-07-24 13:00:00
tags: [paper-review]
class: post-template
subclass: 'post'
author: jaemin
---

DenseNet: Densely Connected Convolutional Networks

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 이재민입니다. :)

제가 이번에 읽은 논문은 **Densely Connected Convolutional Networks**(DenseNet) ([arXiv:1608.06993](https://arxiv.org/abs/1608.06993))이며 2016년 처음 발표가 된 연구입니다. 

![resnet-figure1](/assets/images/posts/2019-07-24-densenet/resnet-figure1.png)

ResNet에서의 shortcut Connection과 같은 Shorter Connection의 연구를 통해 과거보다 더 깊고, 더 정확하며, 더 효율적인 네트워크가 만들어져왔습니다.

이 논문에서는 ResNet과 비슷하지만 다른 네트워크(DenseNet)를 제안하고있습니다.

DenseNet은 아래와 같이 각각의 레이어의 모든 레어어가 모두 feed-forward로 연결되어있는 구조로 되어있습니다.

<img src="/assets/images/posts/2019-07-24-densenet/figure1.png" width="50%" alt="figure1" />

각 DenseBlock의 Convolution Layer는 이전의 모든 Convolution Layer의 Output들과 Concatenate되어 Convolution되게 됩니다. 여기서 ResNet과의 차이점이 들어나게 되는데 ResNet은 과거의 Feature Map이 서로 더해지는 반면에 DenseNet에서는 각 Feature Map들이 Concat 되는 것입니다. 이를 통해 DenseNet은 과거의 Feature Map과 현재의 Feature Map이 서로 섞이지 않고 학습이 될 수 있도록 합니다.

이러한 구조는 아래와 같은 장점을 발생시킵니다.

1. Vanishing-gradient 문제 완화
2. 더 강력한 피쳐 프로파게이션이 가능
3. 피쳐 재사용을 촉진
4. 파라미터의 수를 감소
5. Regularlizing 효과와 Overfitting 감소

그리고 이 논문은 여러 벤치마크 DB인 CIFAR10, CIFAR100, SVHN, ImageNet에서 검증되었고, 논문발표 당시 state-of-the-art를 달성했습니다.

### Architecture

<img src="/assets/images/posts/2019-07-24-densenet/table1.png" width="80%" alt="table1" />

DenseNet은 표와 같은 구조로 설계가 되어있습니다. 여기에서 차별점이 되는 Dense Block과, Transition Block을 한번 알아봅시다. 

**Dense Block**

Dense Block은 DenseNet의 가장 중요한 컨셉이 포함된 블록입니다.  

<img src="/assets/images/posts/2019-07-24-densenet/figure1.png" width="50%" alt="figure1" />

위의 사진과 같이 각 레이어는 이전의 레이어의 Output을 계속 Concat하여 Feed-forward 합니다. 그러다 보면 어느 지점에서는 채널이 아주 커지는 경우가 생길 수 있는데, 이 때문에 이 논문에서는 `Growth rate`이라는 개념을 도입합니다. 각 블록의 Convolution들은 Growth rate만큼의 채널만 Output하여 너무 큰 Output이 발생하지 않도록 해줍니다. 따라서, 위 그림은 Growth rate가 4인 경우의 그림입니다.

**Transition Block**

DenseNet은 Feature를 Down-sampling하기 위해 Transition Block을 사용합니다. Transition Block은  1x1 Convolution과 average pooling으로 구성이 돠어있으며, DenseNet의 하이퍼파라미터인 `theta`값을 통해 다운샘플링하게 됩니다. 기본으로는 theta에 0.5를 주어 average pooling시 stride를 2 (1/theta)로 주어 다운샘플링하게 됩니다.

### Experimental Result

<img src="/assets/images/posts/2019-07-24-densenet/table2.png" width="80%" alt="table2" />

본 논문에서는 여러 환경에서의 실험을 진행하였는데, DesneNet이 가장 뛰여난 성능을 보이는 것으로 나타났습니다.(수치는 test error(%))


### Implementation of DenseNet for CIFAR10

실제 논문을 `pytorch`를 통해 모델을 구현해보았고, 코드는 [https://github.com/J911/DenseNet-pytorch](https://github.com/J911/DenseNet-pytorch)에 배포해 두었습니다.

<img src="/assets/images/posts/2019-07-24-densenet/result.png" width="80%" alt="table2" />

| color|growth_rate|theta|dropout|              scheduler|test error(%)|
|:----:|:---------:|:---:|:-----:|:---------------------:|------------:|
|Orange|         32|  0.5|    0.5|lr_decay [60, 120, 160]|         5.45| 
|  Blue|         32|  0.5|    0.0|lr_decay [60, 120, 160]|         7.08|
|  Pink|         32|  0.5|    0.0|      CosineAnnealingLR|         4.86|


## References
- Huang, Gao, et al. "Densely connected convolutional networks." Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.
