---
layout: post
current: post
cover:  assets/images/posts/2019-11-03-nonlocal/cover.png
navigation: True
title: Non-local Neural Networks
date: 2019-11-03 02:00:00
tags: [paper-review]
class: post-template
subclass: 'post'
author: jaemin
---

오늘 소개할 논문은 Non-local Neural Networks ([arXiv:1711.07971](https://arxiv.org/abs/1711.07971))이며, CVPR2018에서 소개된 논문입니다.

### Introduction
기존의 Convolution Neural Networks들은 3x3, 5x5과 같은 작은 Filter를 거치며 국소적인 피쳐의 특성을 추출해 낼 수 있기 때문에, Pooling과 함께 사용하며 많은 SOTA Architecture들을 만들어냈습니다.

하지만, 이러한 CNN 구조는 피쳐의 특수한 특성을 추출 하는 것에 대하여는 훌륭한 퍼포먼스를 보이지만, 영상의 전체의 Context를 보는 것에는 한계를 보이고 있습니다. 이번에 소개시켜드리는 Non-local Neural Networks는 기존의 Non-local Mean Filter에서 착안을 하여 네트워크가 입력의 전체적인 Context역시 학습할 수 있도록 도와줍니다.

### Non-local Mean Filter
<img src="/assets/images/posts/2019-11-03-nonlocal/non-local-filter.png" width="300px" alt="figure1" />
Non-local Mean Filter는 기존의 영상처리에서 사용되던 denoising 알고리즘으로, 위 사진과 같이 특정 구역에 대하여, 모든 영역에 대하여 유사한 픽셀들을 찾아 평균을 처리하는 방식으로 denoising합니다.

### Non-local Networks
Non-local Networks는 Non-local Block으로 모듈화 되어 CNN 구조 사이에 삽입되어 사용될 수 있습니다.
<img src="/assets/images/posts/2019-11-03-nonlocal/non-local.png" width="60%" alt="figure2" />

위의 다이어그램이 Non-local Block의 다이어그램입니다. 입력된 Input에 대하여 1x1 Conv를 통하여 theta, phi, g를 만들어 낸 뒤 phi의 aixs를 교차해주어 theta와 연산 후 Softmax를 거쳐 모든 맵에 대한 Score Map를 만들어줍니다. 이 맵은 어텐션맵과 유사한 느낌으로 이해가 됩니다. 이 맵과 g를 연산하여 입력에 대하여 어텐션이 적용된 맵을 만들어준뒤 1x1 Conv를 거쳐 기존의 입력과 더하여 출력을하는 구조입니다. 따라서 Non-local 블록은 local한 정보가 아닌 Non-local한 영역까지 학습이 가능한 것입니다.

### Application
Non-local은 General하게 여러 도메인에서 사용될 수 있습니다. 유명한 네트워크들은 Action Recognition에서 I3D + ResNext101 구조에 Non-local Block를 붙인 구조와 Segmentation에 Non-local Block를 붙인 구조들이 있습니다.

**I3D + Non-local**
<img src="/assets/images/posts/2019-11-03-nonlocal/nonlocal-i3d.png" width="80%" alt="figure3" />

위의 결과를 보시면, Optical Flow를 fusion한 다른 Architecture보다 NL을 붙이고 RGB영상만 사용한 구조가 더 높은 성능을 보이고 있습니다.

**CCNet**

<img src="/assets/images/posts/2019-11-03-nonlocal/ccnet.png" width="50%" alt="figure4"/>

Segmentation Task에서도 NL은 좋은 성능을 보입니다. CCNet은 이번 ICCV2019에 소개된 네트워크인데, NL이 연산량이 많은 이슈를 Criss Cross 방식을 통해 연산량은 줄이면서 NL의 효과를 그대로 가져가는 구조를 소개하였습니다.

<img src="/assets/images/posts/2019-11-03-nonlocal/CCNet-result.png" width="60%" alt="figure5"/>

결과를 보면 NL 혹은 RCCA(Recurrent Criss-Cross Attention)를 붙인 네트워크가 CityScapes와 ADE20K 에서 SOTA를 달성한 것을 볼 수 있습니다.

CCNet은 다음번에 자세히 리뷰해 보도록 하겠습니다. 

### Simple implementation of NL
간단한 NL(2D)를 구현해본 코드를 공유합니다.
[https://github.com/J911/DeepLabV3-NonLocal/blob/master/models/NonLocalBlock.py](https://github.com/J911/DeepLabV3-NonLocal/blob/master/models/NonLocalBlock.py)


## References
- Wang, Xiaolong, et al. "Non-local neural networks." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.
- Huang, Zilong, et al. "Ccnet: Criss-cross attention for semantic segmentation." arXiv preprint arXiv:1811.11721 (2018).
