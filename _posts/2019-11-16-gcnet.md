---
layout: post
current: post
cover:  assets/images/posts/2019-11-16-gcnet/figure2.png
navigation: True
title: "GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond"
date: 2019-11-16 02:00:00
tags: [paper-review]
class: post-template
subclass: 'post'
author: jaemin
---

안녕하세요. **AiRLab**(한밭대학교 인공지능 및 로보틱스 연구실) 이재민입니다!
오늘 소개할 논문은 GCNet으로 ([arXiv:1904.11492](https://arxiv.org/abs/1904.11492))으로 이번 ICCV 2019 워크숍에서 소개가 되었던 논문입니다.

이전에 소개시켜드렸던 [Non-local](https://j911.me/2019/11/nonlocal.html)을 시각화하고, 문제점을 지적하는 논문으로 의미가 크다고 생각합니다.

## Non-local 
<img src="/assets/images/posts/2019-11-16-gcnet/non-local.png" width="60%" alt="non-local" />

Non-local Block은 Global Conext를 query-specific하게 접근하는 방식으로 많이 알려져 왔습니다. 

위 그림의 NL 블록을 보더라도 Shape이  HW x HW 로 각 포인트에 대하여 전체 포인트에 대한 Score Map을 만드는 것을 볼 수 있습니다.

이번 GCNet에서는 이러한 필터를 시각화해보았는데요.

<img src="/assets/images/posts/2019-11-16-gcnet/figure2.png" width="60%" alt="figure1" />

위 결과를 보면 각 Point(query)에 대한 NL의 시각화 맵을 볼 수 있는데, 여기서 재밌는 것은 서로 다른 Point에 대하여 모든 결과들이 거의 유사한 heatmap을 보인다는 것입니다. 이는 정량적으로도 확인을 할 수 있는데요.

<img src="/assets/images/posts/2019-11-16-gcnet/figure3.png" width="60%" alt="figure2" />

위의 Method는 여러 Non-local의 종류이고, E-Gaussian(Embedding Gaussian)이 Original NL 입니다.

여기서의 Cosine distance를 보더라고, 서로 다른 InPut에 대하여 큰 차이가 없는 Output이 나오는 것을 정량적으로도 확인을 할 수 있습니다.

## Simplifying the Non-local Block (SNL)

<img src="/assets/images/posts/2019-11-16-gcnet/figure7.png" width="50%" alt="figure6" />

위의 결과처럼 모든 point에서 유사한 heatmap이 나온다고 하면, 충분히 NL의 크기를 줄일 수 있을 것이라고 생각이 드실 겁니다. 논문에서도 이러한 부분을 지적하며 경량화된 Simplifying Non-local Block을 제시하는데요.

<img src="/assets/images/posts/2019-11-16-gcnet/figure4.png" width="50%" alt="figure3" />

위의 수식은 기존의 NL로 각 point i에 대하여, 모든 point j가 연산되는 i, j가 서로 연관적인 것으로 표현이 되고 있습니다. 

하지만 위의 결과처럼 모든 포인트에 대하여, 비슷한 결과가 나오고 있으니 i와 j는 독립적(query independent)으로 아래와 같이 변경해 볼 수 있습니다.

<img src="/assets/images/posts/2019-11-16-gcnet/figure5.png" width="50%" alt="figure4" />

여기서 조금 더 연산량을 줄이기 위해 W(v)를 밖으로 뺌으로서 아래의 SNL이 완셩이 됩니다.

<img src="/assets/images/posts/2019-11-16-gcnet/figure6.png" width="50%" alt="figure5" />

아래 Mask RCNN에서의 결과를 보게 되면 NL과 SNL의 성능이 크게 차이가 나지 않음을(아니 조금더 좋음을?)볼 수 있습니다. 또한 연산량과, Prams를 보더라도 SNL이 훨씬 효율적이여 보입니다.

<img src="/assets/images/posts/2019-11-16-gcnet/figure8.png" width="50%" alt="figure7" />

## Global Context Block

<img src="/assets/images/posts/2019-11-16-gcnet/figure9.png" width="80%" alt="figure8" />

위의 사진처럼 Global Context 모듈들은 Context modeling과 Transform 모델로 분리되어 표현이 될 수 있습니다. 여기서 GCNet은 SNL의 context modeling block 과 SE block의 Transform block이 합쳐진 형태로 구성이 되었습니다. 때문에 SE의 Transform에서 Conv를 2번 나누어 계산 하는 효과인 연산량을 더 낮추는 효과도 가지게 되었습니다.(SNL Transform 연산량: C*C, GCNet 연산량: C*C/r + C/r*C)

<img src="/assets/images/posts/2019-11-16-gcnet/figure10.png" width="50%" alt="figure9" />

이를 위해 하이퍼 파라미터(r) 하나가 추가 되었는데요, 논문에서는 r을 4로 설정한 것이 가장 높은 성능을 보인다고 보여주고 있습니다.

<img src="/assets/images/posts/2019-11-16-gcnet/figure11.png" width="50%" alt="figure10" />

추가적으로 Layer Norm을 추가하여, Normalize 및 Regularize의 효과를 보았다고 합니다.

따라서, 최종적으로 GCNet은 아래 수식 하나로 표현이 되게 됩니다.

<img src="/assets/images/posts/2019-11-16-gcnet/figure12.png" width="50%" alt="figure11" />

## Experiment

<img src="/assets/images/posts/2019-11-16-gcnet/figure12.png" width="50%" alt="figure12" />

논문의 실험은 Mask RCNN과 Classification, Action Recognition에서 실험되었고, 모든 보틀넥에서 GCBlock을 사용한 것이 가장 좋은 성능을 보였습니다.

## 마치며..

이번 논문은 NL의 문제점을 지적하고, NL을 시각화 하는 것만으로도 충분하게 의미기 큰 논문이었던 것 같습니다. 또한 NL의 파라미터와 연산량을 줄여 기존에 한개 혹은 두개만 사용가능 했던 것을 모든 보틀넥에 삽입하여 성능을 크게 키운 것도 인상적입니다. 

하지만, all GCNet처럼, all SNL도 실험 결과가 있었으면 하는 아쉬움도 남습니다.

이번에 ICCV2019를 다녀와서 다음번에 ICCV에 소개되었던 재밌는 논문들을 더 소개시켜드리도록 하겠습니다. 감사합니다 :)

## References

- Cao, Yue, et al. "GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond." arXiv preprint arXiv:1904.11492 (2019).

- [https://j911.me/2019/11/nonlocal.html](https://j911.me/2019/11/nonlocal.html)